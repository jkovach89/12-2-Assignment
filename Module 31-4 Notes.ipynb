{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Name', 'Date', 'Medium', 'Dimensions', 'Acquisition Date',\n",
       "       'Department', 'Classification', 'Diameter (cm)', 'Circumference (cm)',\n",
       "       'Height (cm)', 'Length (cm)', 'Width (cm)', 'Depth (cm)', 'Weight (kg)',\n",
       "       'Duration (s)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, scipy, matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "artworks = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/museum-collection-dataset/artworks.csv')\n",
    "\n",
    "artworks = artworks.drop(['Artwork ID', 'Artist ID', 'Catalogue', 'Object Number', 'Credit',], 1)\n",
    "artworks.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Neural Net\n",
    "\n",
    "Multiple features feeding through a set of perceptron models to each generate a response that will be fed into our final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop films and some other tricky rows.\n",
    "artworks = artworks[artworks['Department']!='Film']\n",
    "artworks = artworks[artworks['Department']!='Media and Performance Art']\n",
    "artworks = artworks[artworks['Department']!='Fluxus Collection']\n",
    "artworks = artworks[artworks['Department']!='Architecture & Design - Image Archive']\n",
    "\n",
    "\n",
    "# Convert acquisition date to numerical format\n",
    "artworks['DateAcquired'] = pd.to_datetime(artworks['Acquisition Date'], errors='coerce')\n",
    "artworks['YearAcquired'] = artworks.DateAcquired.dt.year\n",
    "artworks = artworks.drop(['Acquisition Date', 'DateAcquired', 'Medium'], 1).replace(np.nan, 0)\n",
    "artworks = artworks.dropna(how='any')\n",
    "\n",
    "# Reduce the overall number of observations\n",
    "artworks = artworks.sample(n=10000, random_state=23)\n",
    "\n",
    "# Drop missing data.\n",
    "artworks.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to start date, cutting down number of distinct examples.\n",
    "artworks['Date'] = pd.Series(artworks.Date.str.extract(\n",
    "    '([0-9]{4})', expand=False))[:-1]\n",
    "\n",
    "artists = pd.get_dummies(artworks.Name)\n",
    "artworks = pd.concat([artworks, artists], 1)\n",
    "\n",
    "# Final and N/A drops\n",
    "X = artworks.drop(['Title', 'Department', 'Name', 'Date', 'Dimensions', 'Classification'], 1)\n",
    "Y = artworks.Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 79978 to 49481\n",
      "Columns: 2994 entries, Diameter (cm) to Öyvind Fahlström\n",
      "dtypes: float64(9), uint8(2985)\n",
      "memory usage: 29.2 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8867"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Establish and fit the model, with a single, 100 perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100,))\n",
    "mlp.fit(X, Y)\n",
    "mlp.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prints & Illustrated Books    0.4979\n",
       "Photography                   0.2312\n",
       "Architecture & Design         0.1475\n",
       "Drawings                      0.0951\n",
       "Painting & Sculpture          0.0283\n",
       "Name: Department, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mlp, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "1. Hidden layer size - pass list with the size of each layer, number of layers is equal to items on the list\n",
    "2. Alpha - regularization parameters penalize high coefficients, alpha scales the parameter\n",
    "3. Activation function - determines if perceptron output is binary or continuous\n",
    "\n",
    "RELU or rectified linear unit function - binary\n",
    "\n",
    "sigmoid or logistic sigmoid function - allows for continuous variable 0-1, more nuanced model, less computationally efficient\n",
    "\n",
    "Additional layers helps prevent overfitting, additional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
