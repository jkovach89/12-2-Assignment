{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, scipy, sklearn, spacy, matplotlib.pyplot as plt, seaborn as sns, re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised requires pre-labeled data, predict whether a sentence is from Alice or Persuasion\n",
    "# Works with any model which allows categorical outcomes\n",
    "# Feature generation with BoW_ (Bag of words)\n",
    "# For each sentence, count number of times a word appears, counts are features\n",
    "\n",
    "# Text cleaning function\n",
    "def text_cleaner(text):\n",
    "    # Double dash '--' needs to be removed explicity\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Load and clean data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "\n",
    "# Use only 1/10 of the text to reduce processing time\n",
    "alice = text_cleaner(alice[:int(len(alice)/10)])\n",
    "persuasion = text_cleaner(persuasion[:int(len(persuasion)/10)])\n",
    "\n",
    "# Parsing the cleaned novels\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine to dataframe\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay</th>\n",
       "      <th>nod</th>\n",
       "      <th>waistcoat</th>\n",
       "      <th>preserver</th>\n",
       "      <th>blood</th>\n",
       "      <th>Musgrove</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>outward</th>\n",
       "      <th>neat</th>\n",
       "      <th>poison</th>\n",
       "      <th>...</th>\n",
       "      <th>issue</th>\n",
       "      <th>employ</th>\n",
       "      <th>key</th>\n",
       "      <th>rise</th>\n",
       "      <th>prescribe</th>\n",
       "      <th>severe</th>\n",
       "      <th>read</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_sources</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1615 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stay nod waistcoat preserver blood Musgrove neighbourhood outward neat  \\\n",
       "0    0   0         0         0     0        0             0       0    0   \n",
       "1    0   0         0         0     0        0             0       0    0   \n",
       "2    0   0         0         0     0        0             0       0    0   \n",
       "3    0   0         0         0     0        0             0       0    0   \n",
       "4    0   0         0         0     0        0             0       0    0   \n",
       "\n",
       "  poison  ... issue employ key rise prescribe severe read  \\\n",
       "0      0  ...     0      0   0    0         0      0    1   \n",
       "1      0  ...     0      0   0    0         0      0    0   \n",
       "2      0  ...     0      0   0    0         0      0    0   \n",
       "3      0  ...     0      0   0    0         0      0    0   \n",
       "4      0  ...     0      0   0    0         0      0    0   \n",
       "\n",
       "                                       text_sentence text_sources  \\\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...      Carroll   \n",
       "1  (So, she, was, considering, in, her, own, mind...      Carroll   \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...      Carroll   \n",
       "3                                      (Oh, dear, !)      Carroll   \n",
       "4                                      (Oh, dear, !)      Carroll   \n",
       "\n",
       "  sentence_length  \n",
       "0              67  \n",
       "1              63  \n",
       "2              30  \n",
       "3               3  \n",
       "4               3  \n",
       "\n",
       "[5 rows x 1615 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function to define the 2000 most common words\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter punctionation and stopwords\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return 2000 most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "# Create DF with features for each word in our common word set\n",
    "# Values are the count of the times the word appears in each sentence\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the DF and initialize counts to 0\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_sources'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurance of words in each sentence\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert to lemmas, filter out punctuation, stopwords and uncommon words \n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words)]\n",
    "        \n",
    "        # Populate rows with word counts\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # Checks for hung kernel\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Set up bags\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine two bags to create a set of unique words\n",
    "common_words = set(alicewords + persuasionwords)\n",
    "\n",
    "# Create dataset with features. Computationally intensive\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "\n",
    "# Minimal feature engineering due to time constraints\n",
    "def sentence_length(sent):\n",
    "    return len(sent)\n",
    "word_counts['sentence_length'] = word_counts['text_sentence'].apply(sentence_length)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Score: 0.985239852398524\n",
      "Test Set Score: 0.8453038674033149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkovach/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Using bag of words dataset with random forest model\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_sources']\n",
    "X = np.array(word_counts.drop(['text_sentence', 'text_sources'], 1))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4,\n",
    "                                                   random_state=0)\n",
    "\n",
    "train = rfc.fit(X_train, Y_train)\n",
    "print(\"Training Set Score:\", rfc.score(X_train, Y_train))\n",
    "print(\"Test Set Score:\", rfc.score(X_test, Y_test))\n",
    "\n",
    "# Overfitting is a known issue in bag-of-words, also random forests. \n",
    "# Disparity between train/test set expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 1613) (271,)\n",
      "Training Set Score: 0.9520295202952029\n",
      "Test Set Score: 0.8342541436464088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkovach/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, Y_train)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(\"Training Set Score:\", lr.score(X_train, Y_train))\n",
    "print(\"Test Set Score:\", lr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Score: 0.985239852398524\n",
      "Test Set Score: 0.850828729281768\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words with gradient boosting\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, Y_train)\n",
    "print(\"Training Set Score:\", clf.score(X_train, Y_train))\n",
    "print(\"Test Set Score:\", clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For increasing performance, I created a feature for sentence length and attempted SVM to see if it was better suited. I understand the necessity of thorough feature engineering, but chose to move on quickly due to time constraints. \n",
    "\n",
    "Including sentence length seemed to reduce the performance of logistic regression while increasing performance of gradient boosting and random forest. SVM performance performed slightly worse than logistic regression prior to inclusion of this new feature, but was the best performer after inclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Score: 0.988929889298893\n",
      "Test Set Score: 0.8839779005524862\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "train = svm.fit(X_train, Y_train)\n",
    "print(\"Training Set Score:\", svm.score(X_train, Y_train))\n",
    "print(\"Test Set Score:\", svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n",
      "Processing row 350\n",
      "Processing row 400\n",
      "Processing row 450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>school</th>\n",
       "      <th>pierce</th>\n",
       "      <th>important</th>\n",
       "      <th>WALW</th>\n",
       "      <th>mariner</th>\n",
       "      <th>waistcoat</th>\n",
       "      <th>bit</th>\n",
       "      <th>fancy</th>\n",
       "      <th>lowly</th>\n",
       "      <th>...</th>\n",
       "      <th>vent</th>\n",
       "      <th>stream</th>\n",
       "      <th>LATIN</th>\n",
       "      <th>Europe</th>\n",
       "      <th>later</th>\n",
       "      <th>POCKET</th>\n",
       "      <th>Fife</th>\n",
       "      <th>read</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label school pierce important WALW mariner waistcoat bit fancy lowly  ...  \\\n",
       "0     0      0      0         0    0       0         0   0     0     0  ...   \n",
       "1     0      0      0         0    0       0         0   0     0     0  ...   \n",
       "2     0      0      0         0    0       0         0   0     0     0  ...   \n",
       "3     0      0      0         0    0       0         0   0     0     0  ...   \n",
       "4     0      0      0         0    0       0         0   0     0     0  ...   \n",
       "\n",
       "  vent stream LATIN Europe later POCKET Fife read  \\\n",
       "0    0      0     0      0     0      0    0    1   \n",
       "1    0      0     0      0     0      0    0    0   \n",
       "2    0      0     0      0     0      0    0    0   \n",
       "3    0      0     0      0     0      0    0    0   \n",
       "4    0      0     0      0     0      0    0    0   \n",
       "\n",
       "                                       text_sentence text_sources  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...      Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...      Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...      Carroll  \n",
       "3                                      (Oh, dear, !)      Carroll  \n",
       "4                                      (Oh, dear, !)      Carroll  \n",
       "\n",
       "[5 rows x 1221 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge #1: I chose to compare Moby Dick (published in 1851) with Alice in Wonderland (published 1865)\n",
    "moby = gutenberg.raw('melville-moby_dick.txt')\n",
    "moby = text_cleaner(moby[:int(len(moby)/80)])\n",
    "\n",
    "moby_doc = nlp(moby)\n",
    "moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "sentences = pd.DataFrame(alice_sents + moby_sents)\n",
    "\n",
    "mobywords = bag_of_words(moby_doc)\n",
    "common_words = set(alicewords + mobywords)\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Score: 0.9520295202952029\n",
      "Test Set Score: 0.8342541436464088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkovach/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Carroll</th>\n",
       "      <th>Melville</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_sources</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Carroll</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Melville</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         Carroll  Melville\n",
       "text_sources                   \n",
       "Carroll            25        28\n",
       "Melville            2       126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Moby versus Alice with logistic regression\n",
    "lr.fit(X_train, Y_train)\n",
    "print(\"Training Set Score:\", lr.score(X_train, Y_train))\n",
    "print(\"Test Set Score:\", lr.score(X_test, Y_test))\n",
    "lr_preds = lr.predict(X_test)\n",
    "pd.crosstab(Y_test, lr_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
